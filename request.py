import json
import requests
from bs4 import BeautifulSoup
from datetime import datetime
from urllib.parse import urlparse

# –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã –¥–ª—è —Ü–≤–µ—Ç–Ω–æ–≥–æ –≤—ã–≤–æ–¥–∞
GREEN = '\033[92m'
RED = '\033[91m'
ORANGE = '\033[93m'
RESET = '\033[0m'

# –ë–∞–∑–æ–≤—ã–π URL
BASE_URL = 'https://kotelbk.ru/sveden/'
BASE_URL = 'https://academicol.ru/sveden/'
BASE_URL = 'https://kamkb.ru/sveden/'

# –ü–æ–ª—É—á–∞–µ–º –¥–æ–º–µ–Ω –∏–∑ BASE_URL
DOMAIN = urlparse(BASE_URL).netloc

# –°–ª–æ–≤–∞—Ä—å —Å—Ç—Ä–∞–Ω–∏—Ü
PAGES = {
    'common': '–û—Å–Ω–æ–≤–Ω—ã–µ —Å–≤–µ–¥–µ–Ω–∏—è',
    'struct': '–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –∏ –æ—Ä–≥–∞–Ω—ã —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–æ–π –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–µ–π',
    'document': '–î–æ–∫—É–º–µ–Ω—Ç—ã',
    'education': '–û–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ',
    'eduStandarts': '–û–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω—ã–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç—ã –∏ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è',
    'managers': '–†—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ',
    'employees': '–ü–µ–¥–∞–≥–æ–≥–∏—á–µ—Å–∫–∏–π —Å–æ—Å—Ç–∞–≤',
    'objects': '–ú–∞—Ç–µ—Ä–∏–∞–ª—å–Ω–æ-—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–µ –æ–±–µ—Å–ø–µ—á–µ–Ω–∏–µ –∏ –æ—Å–Ω–∞—â—ë–Ω–Ω–æ—Å—Ç—å –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–æ–≥–æ –ø—Ä–æ—Ü–µ—Å—Å–∞. –î–æ—Å—Ç—É–ø–Ω–∞—è —Å—Ä–µ–¥–∞',
    'grants': '–°—Ç–∏–ø–µ–Ω–¥–∏–∏ –∏ –º–µ—Ä—ã –ø–æ–¥–¥–µ—Ä–∂–∫–∏ –æ–±—É—á–∞—é—â–∏—Ö—Å—è',
    'paid_edu': '–ü–ª–∞—Ç–Ω—ã–µ –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω—ã–µ —É—Å–ª—É–≥–∏',
    'budget': '–§–∏–Ω–∞–Ω—Å–æ–≤–æ-—Ö–æ–∑—è–π—Å—Ç–≤–µ–Ω–Ω–∞—è –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç—å',
    'vacant': '–í–∞–∫–∞–Ω—Ç–Ω—ã–µ –º–µ—Å—Ç–∞ –¥–ª—è –ø—Ä–∏—ë–º–∞ (–ø–µ—Ä–µ–≤–æ–¥–∞) –æ–±—É—á–∞—é—â–∏—Ö—Å—è',
    'inter': '–ú–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω–æ–µ —Å–æ—Ç—Ä—É–¥–Ω–∏—á–µ—Å—Ç–≤–æ',
    'catering': '–û—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è –ø–∏—Ç–∞–Ω–∏—è –≤ –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–æ–π –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏',
}

def read_json_file(filename):
    try:
        with open(filename, 'r', encoding='utf-8') as file:
            return json.load(file)
    except FileNotFoundError:
        print(f"–û—à–∏–±–∫–∞: –§–∞–π–ª {filename} –Ω–µ –Ω–∞–π–¥–µ–Ω.")
        return None
    except json.JSONDecodeError:
        print(f"–û—à–∏–±–∫–∞: –ù–µ–≤–æ–∑–º–æ–∂–Ω–æ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞—Ç—å JSON –∏–∑ —Ñ–∞–π–ª–∞ {filename}.")
        return None

def color_print(text, color):
    print(f"{color}{text}{RESET}")

def match_slug_to_section(slug):
    return PAGES.get(slug, "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è —Å–µ–∫—Ü–∏—è")

def generate_html_report(results):
    html_content = f"""
    <html>
    <head>
        <meta charset="UTF-8">
        <title>–û—Ç—á–µ—Ç –ø–æ –∞–Ω–∞–ª–∏–∑—É {DOMAIN}</title>
        <style>
            body {{ font-family: Arial, sans-serif; }}
            .found {{ color: green; }}
            .missing {{ color: red; }}
            .page {{ margin-bottom: 20px; border-bottom: 1px solid #ccc; }}
        </style>
    </head>
    <body>
        <h1>–û—Ç—á–µ—Ç –ø–æ –∞–Ω–∞–ª–∏–∑—É {DOMAIN}</h1>
        <p>–î–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
        {''.join(results)}
    </body>
    </html>
    """
    return html_content

def analyze_page(url, section_name, itemprops):
    try:
        response = requests.get(url)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, 'html.parser')

        found_items = []
        missing_items = []
        hidden_items = []

        for prop in itemprops:
            if prop in ['parent', 'child']:
                continue

            element = soup.find(attrs={"itemprop": prop})
            if element:
                if element.has_attr('class') and 'hidden' in element.get('class') and element.text.strip() == "–î–∞–Ω–Ω—ã–µ –æ–±–Ω–æ–≤–ª—è—é—Ç—Å—è":
                    hidden_items.append(prop)
                else:
                    found_items.append(prop)
            else:
                missing_items.append(prop)

        # –û–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π –≤—ã–≤–æ–¥ –≤ –∫–æ–Ω—Å–æ–ª—å
        print(f"\n–ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä–∞–Ω–∏—Ü—ã: {url}")
        print(f"\n–°–µ–∫—Ü–∏—è: {section_name}\n")
        print("–ù–∞–π–¥–µ–Ω–Ω—ã–µ itemprop:")
        for item in found_items:
            color_print(f"‚úÖ {item}", GREEN)
        if hidden_items:
            print("\n–°–∫—Ä—ã—Ç—ã–µ itemprop:")
            for item in hidden_items:
                color_print(f"üî∏ {item}", ORANGE)
        if missing_items:
            print("\n–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ itemprop:")
            for item in missing_items:
                color_print(f"‚ùå {item}", RED)
        print(f"\n–ò—Ç–æ–≥–æ: {len(found_items)} –Ω–∞–π–¥–µ–Ω–æ, {len(hidden_items)} —Å–∫—Ä—ã—Ç–æ, {len(missing_items)} –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç")

        # –û–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π HTML-—Ñ—Ä–∞–≥–º–µ–Ω—Ç –¥–ª—è –æ—Ç—á–µ—Ç–∞
        html_content = f"""
        <div class="page">
            <h2>–ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä–∞–Ω–∏—Ü—ã: {url}</h2>
            <h3>–°–µ–∫—Ü–∏—è: {section_name}</h3>
            <h4>–ù–∞–π–¥–µ–Ω–Ω—ã–µ itemprop:</h4>
            <ul>
                {''.join(f'<li class="found">‚úÖ {item}</li>' for item in found_items)}
            </ul>
        """
        if hidden_items:
            html_content += f"""
            <h4>–°–∫—Ä—ã—Ç—ã–µ itemprop:</h4>
            <ul>
                {''.join(f'<li class="hidden">üî∏ {item}</li>' for item in hidden_items)}
            </ul>
            """
        if missing_items:
            html_content += f"""
            <h4>–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ itemprop:</h4>
            <ul>
                {''.join(f'<li class="missing">‚ùå {item}</li>' for item in missing_items)}
            </ul>
            """
        html_content += f"""
            <p>–ò—Ç–æ–≥–æ: {len(found_items)} –Ω–∞–π–¥–µ–Ω–æ, {len(hidden_items)} —Å–∫—Ä—ã—Ç–æ, {len(missing_items)} –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç</p>
        </div>
        """
        return html_content

    except requests.RequestException as e:
        error_message = f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ {url}: {e}"
        print(error_message)
        return f"<div class='page'><p style='color: red;'>{error_message}</p></div>"

def main():
    itemprop_data = read_json_file('_itemprop.json')
    if itemprop_data is None:
        print("–ù–µ–≤–æ–∑–º–æ–∂–Ω–æ –ø—Ä–æ–¥–æ–ª–∂–∏—Ç—å –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –±–µ–∑ –¥–∞–Ω–Ω—ã—Ö JSON.")
        return
    
    results = []
    for slug, section_name in PAGES.items():
        url = BASE_URL + slug
        section_data = next((s for s in itemprop_data['sections'] if s['section'] == section_name), None)
        if section_data:
            result = analyze_page(url, section_name, section_data['itemprops'])
            results.append(result)
        else:
            print(f"–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –î–∞–Ω–Ω—ã–µ –¥–ª—è —Å–µ–∫—Ü–∏–∏ '{section_name}' –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ JSON.")

    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º HTML-–æ—Ç—á–µ—Ç
    html_report = generate_html_report(results)
    report_filename = f"itemprop_report_{DOMAIN}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.html"
    with open(report_filename, 'w', encoding='utf-8') as f:
        f.write(html_report)
    print(f"\n–û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ —Ñ–∞–π–ª: {report_filename}")

if __name__ == "__main__":
    main()